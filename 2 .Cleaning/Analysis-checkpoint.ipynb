{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d234763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "import seaborn as sns\n",
    "from fim import arules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f445a2b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fact_table.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fact_table \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfact_table.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fact_table.csv'"
     ]
    }
   ],
   "source": [
    "fact_table = pd.read_csv('fact_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a10ed",
   "metadata": {},
   "source": [
    "# Lets Explore and Understand the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651cdbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales Trends Over Time + line \n",
    "# product items\n",
    "# top customers\n",
    "# sales by location\n",
    "# Payment Method Preferences\n",
    "# Time of Day Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784e242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fact_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdbd993",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = pd.read_csv('item_dim.csv',  encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26da7054",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = pd.read_csv('customer_dim.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.read_csv('store_dim.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dim = pd.read_csv('time_dim.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33f559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = pd.read_csv('Trans_dim.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1508ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(fact_table, time_dim, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c89a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, trans, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c672f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, store, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ba909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, item, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, customer, how='inner')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810416be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88225be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['unit'].isnull()].sort_values('item_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "item[item['item_key'] == 'I00158']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae4198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unit'].fillna('Frito Bold Flavors Variety', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b98fed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088fc25c",
   "metadata": {},
   "source": [
    "# RFM Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cef5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time_difference to capture part of data below\n",
    "df[\"time_difference\"] = df['date'].max() - df[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last two years\n",
    "df[\"last_two_years\"] = df[\"time_difference\"] <= timedelta(days=2*365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f58d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFM = df[df['last_two_years']==True].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b5efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFM['Recency'] = (df_RFM['date'].max() - df_RFM['date']).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f592f",
   "metadata": {},
   "source": [
    "### Using group by for each customer we need we create three now columns as following"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c2de1",
   "metadata": {},
   "source": [
    " -Recency: for each customer snapshot date – latest purchase difference in days\n",
    " \n",
    " -Frequency: for each customer count of how many invoices are issued for him\n",
    " \n",
    " -Monetary Value: for each customer sum of amount spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218365b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFM = df_RFM.groupby(['coustomer_key']).agg({'Recency': np.min,\n",
    "                                           'date':pd.Series.nunique,\n",
    "                                           'total_price':np.sum}).reset_index()\n",
    "\n",
    "df_RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns\n",
    "df_RFM.rename(columns={'Recency':'Recency','date':'Frequency','total_price':'Monetary'},inplace= True)\n",
    "\n",
    "df_RFM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47303bc1",
   "metadata": {},
   "source": [
    "### We have now calculated our values. But those aggregations are absolut and hard to explain as is. It is better to normalize our scores replacing those values with relative once with respect to the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de66c8c7",
   "metadata": {},
   "source": [
    "### Pandas qcut splits numeric columns into quartiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b0aeec",
   "metadata": {},
   "source": [
    "### For Recency and Frequency columns, the higher values (top quartile) are assigned with indicator 4 and lowest to 1. Higher values imply that customers have spent more money to our products or bought more often and the 1-4 score is assigned accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e783fe",
   "metadata": {},
   "source": [
    "### The opposite logic is applied for recency as higher values mean that many days have passed since last purchase. Thus, customers with high values (top quartile) take score 1 and those with the smallest values 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de17aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Scores RFM scores based on quantiles of distribution\n",
    "\n",
    "#Date from customer's last purchase.The nearest date gets 4 and the furthest date gets 1.\n",
    "df_RFM[\"recency_score\"] = pd.qcut(df_RFM['Recency'].rank(method=\"first\"),\n",
    "                                  4,\n",
    "                                  labels=[4, 3, 2, 1])\n",
    "\n",
    "# Total number of purchases.The least frequency gets 1 and the maximum frequency gets 4.\n",
    "df_RFM[\"frequency_score\"] = pd.qcut(df_RFM[\"Frequency\"].rank(method=\"first\"),\n",
    "                                    4,\n",
    "                                    labels=[1, 2, 3, 4])\n",
    "\n",
    "#Total spend by the customer.The least money gets 1, the most money gets 4.\n",
    "df_RFM[\"monetary_score\"] = pd.qcut(df_RFM[\"Monetary\"].rank(method=\"first\"),\n",
    "                                   4,\n",
    "                                   labels=[1, 2, 3, 4])\n",
    "\n",
    "df_RFM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a071a6f8",
   "metadata": {},
   "source": [
    "## Calculate total RFM score for each customer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf326d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFM[\"RFM_Segment\"] = df_RFM[\"recency_score\"].astype(str) + df_RFM[\n",
    "    \"frequency_score\"].astype(str) + df_RFM[\"monetary_score\"].astype(str)\n",
    "\n",
    "df_RFM['RFM_Score'] = df_RFM[[\n",
    "    'recency_score', 'frequency_score', 'monetary_score'\n",
    "]].sum(axis=1)\n",
    "df_RFM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f24d9e",
   "metadata": {},
   "source": [
    "### Split customers to segments and give indicative names (labeling appoaches may vary for this step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be12ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "segt_map = {\n",
    "    r'[3-4][3-4]4': 'VIP',\n",
    "    r'[2-3-4][1-2-3-4]4': 'Top Recent',\n",
    "    r'1[1-2-3-4]4': 'Top at Risk ',\n",
    "\n",
    "    \n",
    "    \n",
    "    r'[3-4][3-4]3': 'High Promising',\n",
    "    r'[2-3-4][1-2]3': 'High New',\n",
    "    r'2[3-4]3': 'High Loyal',\n",
    "\n",
    "    \n",
    "    \n",
    "    r'[3-4][3-4]2': 'Medium Potential',\n",
    "    r'[2-3-4][1-2]2': 'Medium New',\n",
    "    r'2[3-4]2': 'Medium Loyal',\n",
    "\n",
    "    \n",
    "    \n",
    "    r'4[1-2-3-4]1': 'Low New',\n",
    "    r'[2-3][1-2-3-4]1': 'Low Loyal',\n",
    "    \n",
    "    r'1[1-2-3-4][1-2-3]': 'Need Activation'\n",
    "}\n",
    "df_RFM['Segment_labels'] = df_RFM['RFM_Segment']\n",
    "df_RFM['Segment_labels'] = df_RFM['Segment_labels'].replace(segt_map, regex=True)\n",
    "df_RFM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26da1439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_pareto = df_RFM.groupby([\"Segment_labels\"]).agg({'Monetary': np.sum,\n",
    "                 \n",
    "                                                           \"coustomer_key\": pd.Series.nunique}).reset_index()\n",
    "\n",
    "seg_pareto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c8acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_pareto[\"Monetary%\"] = seg_pareto[\"Monetary\"]/seg_pareto[\"Monetary\"].sum()\n",
    "seg_pareto = seg_pareto.sort_values(by=['Monetary%'], ascending=False)\n",
    "seg_pareto[\"CumulativePercentage\"] = (seg_pareto[\"Monetary\"].cumsum()/ \n",
    "                                      seg_pareto[\"Monetary\"].sum()*100).round(2)\n",
    "seg_pareto[\"CumulativeSum\"] = (seg_pareto[\"coustomer_key\"].cumsum()/ \n",
    "                                      seg_pareto[\"coustomer_key\"].sum()*100).round(2)\n",
    "\n",
    "seg_pareto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884b495e",
   "metadata": {},
   "source": [
    "# Market Basket Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b28597d",
   "metadata": {},
   "source": [
    "## Association Rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b8c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18348ae",
   "metadata": {},
   "source": [
    "## 1 - Produce an Association Rules Report which will show the below measures: \n",
    "### support itemset absolute, support itemset relative pct, confidence pct and lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62933eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "supp = 10  # minimum support of an assoc. rule (default: 10)\n",
    "conf = 80  # minimum confidence of an assoc. rule (default: 80%)\n",
    "zmin = 2\n",
    "zmax = 2\n",
    "report = 'aSCl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b46d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_colnames = {\n",
    "    'a': 'support_itemset_absolute',\n",
    "    's': 'support_itemset_relative',\n",
    "    'S': 'support_itemset_relative_pct',\n",
    "    'b': 'support_bodyset_absolute',\n",
    "    'x': 'support_bodyset_relative',\n",
    "    'X': 'support_bodyset_relative_pct',\n",
    "    'h': 'support_headitem_absolute',\n",
    "    'y': 'support_headitem_relative',\n",
    "    'Y': 'support_headitem_relative_pct',\n",
    "    'c': 'confidence',\n",
    "    'C': 'confidence_pct',\n",
    "    'l': 'lift',\n",
    "    'L': 'lift_pct',\n",
    "    'e': 'evaluation',\n",
    "    'E': 'evaluation_pct',\n",
    "    'Q': 'support of the empty set (total number of transactions)'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_prod=df.groupby('coustomer_key')['item_name'].apply(list)\n",
    "cust_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb8bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of lists to pass it into PyFim\n",
    "\n",
    "cust_prod_list=cust_prod.to_list()\n",
    "cust_prod_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run apriori algorithm to creeate associations\n",
    "apriori = arules(cust_prod_list, supp=supp, conf=conf, report=report,eval='lift', zmin = 2,zmax = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment and run in case you want to see parameters of association rules\n",
    "#??arules \n",
    "\n",
    "\n",
    "#Creat dataframe wiht columns based on the report variables and sorted based on the \"Associations_Sorted_based_on\"\n",
    "colnames = ['Cons_Product', 'antecedent'] + [report_colnames.get(k, k) for k in list(report)]\n",
    "df_rules = pd.DataFrame(apriori, columns=colnames)\n",
    "df_rules = df_rules.sort_values(report_colnames[\"a\"], ascending=False)\n",
    "\n",
    "#Change order of columns antecedent and consequent\n",
    "df_rules = df_rules[['antecedent', 'Cons_Product']+ [report_colnames.get(k, k) for k in list(report)]]\n",
    "\n",
    "\n",
    "#Print the numbers of rules created\n",
    "print(df_rules.shape)\n",
    "\n",
    "#Print top 10 and last 10 rules (the last 10 will be shown)\n",
    "df_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3fd29c",
   "metadata": {},
   "source": [
    "## 2 - Find the Top5 Association in terms of Support Absolute, confidence and lift and provide an interpretation of your results for these product relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6852c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules = df_rules.sort_values(by='lift', ascending=False)\n",
    "df_rules.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules = df_rules.sort_values(by='confidence_pct', ascending=False)\n",
    "df_rules.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a30c001",
   "metadata": {},
   "source": [
    "## 3 - Is there product cannibalization between products? If yes, provide for which products. If not, support your statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc37155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules = df_rules.sort_values(by='lift', ascending=True)\n",
    "df_rules.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
